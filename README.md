# AMT-GAF
Asymmetric Multi-Task system for Gaze-driven grasping Action Forecasting
### [Project Page](https://companion-cm.webs.tsc.uc3m.es/) | [Paper](https://ieeexplore.ieee.org/abstract/document/10602750)

> [Asymmetric Multi-Task system for Gaze-driven grasping Action Forecasting](https://ieeexplore.ieee.org/abstract/document/10602750)  
> Iván González Díaz, Miguel Molina-Moreno, Jenny Benois-Pineau and Aymar de Rugy
> IEEE Journal of Biomedical and Health Informatics, 2024 
> doi: 10.1109/JBHI.2024.3430810.

## Citation
If you find our code or paper useful, please consider citing our paper:
```BibTeX
@ARTICLE{10602750,

  author={González-Diaz, Iván and Molina-Moreno, Miguel and Benois-Pineau, Jenny and de Rugy, Aymar},

  journal={IEEE Journal of Biomedical and Health Informatics}, 

  title={Asymmetric multi-task learning for interpretable gaze-driven grasping action forecasting}, 

  year={2024},

  volume={},

  number={},

  pages={1-17},

  keywords={Task analysis;Predictive models;Visualization;Multitasking;Grasping;Forecasting;Hidden Markov models;Grasping action forecasting;multi-task learning;interpretable attention prediction;constrained loss},

  doi={10.1109/JBHI.2024.3430810}
 }
